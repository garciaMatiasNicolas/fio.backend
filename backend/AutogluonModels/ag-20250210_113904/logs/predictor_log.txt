Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113904'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.2485       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.2485
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113906'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-4.2552       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -4.2552
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113908'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9969       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9969
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113910'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6848       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6848
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113912'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7702       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7702
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113914'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9560       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9560
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113916'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9106       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9106
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113918'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0027       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0027
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113920-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9911       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9911
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113922-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113924'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113926-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.42 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7990       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7990
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113928-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9915       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9915
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113930-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8920       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8920
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113932-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7443       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.91 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7443
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113934-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3237       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3237
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113936-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.5557       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.5557
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113938-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3698       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3698
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113940-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9670       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9670
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113942-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8606       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8606
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113944-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7346       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7346
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113946'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113948'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113949-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9653       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9653
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113951-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.3477       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.3477
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113953-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.5%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6517       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6517
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113955-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9680       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9680
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_113958'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:39:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114000'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8897       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8897
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114003-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.52 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8487       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8487
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114005-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3122       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.04 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3122
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114007-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.2091       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.2091
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114009-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9733       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9733
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114011-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4290       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4290
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114013-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:13
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8822       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8822
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114015-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:15
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5276       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5276
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114018'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8463       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8463
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114020'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-4.2779       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -4.2779
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114022'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5078       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.52    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.54 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5078
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114024'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0934       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0934
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114027'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:27
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4539       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4539
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114029'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:29
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114031'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:31
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8192       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8192
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114033'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:33
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5749       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5749
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114035'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:35
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4899       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4899
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114037'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:37
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0714       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0714
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114039'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:39
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6031       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6031
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114041'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:41
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-7.3720       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -7.3720
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114043'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7689       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.23    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.25 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7689
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114045'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:45
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6585       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6585
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114047'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9860       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9860
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114049'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114051'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5960       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5960
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114053'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9931       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9931
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114055'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9410       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9410
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114057'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114059'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.7704       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.7704
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114101'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9582       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9582
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114103'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114105'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114107'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114109'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114111'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:11
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114113'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:13
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7690       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7690
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114115'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:15
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5027       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5027
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114117'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:17
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6845       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.57    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.60 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6845
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114119-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.49 GB / 7.75 GB (32.1%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:19
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0121       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0121
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114121-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.44 GB / 7.75 GB (31.4%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:21
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8964       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8964
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114123'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:23
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7747       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7747
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114125-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:25
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114127-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:27
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114129'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:29
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.40    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.43 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114132'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5359       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.91 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5359
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114133-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:33
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4672       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4672
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114135-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:35
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9152       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9152
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114137'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:37
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8130       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8130
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114139'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:39
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8162       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.13 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8162
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114142'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4915       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4915
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114144'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4083       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4083
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114146'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-3.2296       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -3.2296
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114148'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.6349       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.6349
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114149-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5805       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5805
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114151-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.7727       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.7727
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114153-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7197       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7197
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114155-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8419       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8419
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114157-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-3.0100       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -3.0100
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114159-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5065       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.20    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.22 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5065
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114201-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0060       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0060
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114203-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4567       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.04 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4567
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114205-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.2974       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2974
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114207'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6906       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6906
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114209-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3083       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3083
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114212-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114214-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7498       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7498
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114216-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1991       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1991
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114218-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4596       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4596
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114220-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-4.7212       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -4.7212
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114222-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114224-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.4633       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.4633
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114226-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8946       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8946
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114228'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6998       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6998
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114230'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7845       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7845
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114232'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6916       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.91 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6916
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114234'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9315       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9315
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114236'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5954       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5954
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114238'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7957       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7957
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114240'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3781       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3781
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114242'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4379       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4379
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114243'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9835       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9835
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114245'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.7162       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.26    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.30 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.7162
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114248-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9848       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.09 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9848
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114250-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8162       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8162
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114252-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.2603       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2603
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114254-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1034       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1034
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114256-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:56
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6424       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6424
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114258-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0761       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0761
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114300'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114302'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3968       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.28    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.32 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3968
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114305-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114307-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9867       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9867
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114309-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9347       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9347
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114311-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:11
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6173       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6173
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114314'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0045       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0045
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114316-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4114       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4114
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114318-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114320-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9771       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9771
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114322-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114324-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114326-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114328-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0041       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.22    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.25 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0041
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114330-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0077       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0077
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114332-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9998       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9998
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114334-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-4.3459       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -4.3459
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114336-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9919       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9919
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114338'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7301       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7301
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114340'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114342'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114344'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1345       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1345
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114346'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8690       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8690
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114348'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114350'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9179       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9179
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114352'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8098       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8098
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114354-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9404       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9404
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114357'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.2118       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2118
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114359'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-3.5830       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -3.5830
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114401'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8996       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8996
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114402-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9913       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9913
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114404-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5244       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5244
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114406-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8027       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8027
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114408-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8707       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8707
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114410-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.2789       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.04 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2789
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114412-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4092       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4092
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114414-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.9221       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.9221
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114416-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1550       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1550
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114418-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6901       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6901
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114421'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:21
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9975       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9975
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114423'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:23
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8003       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8003
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114425'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:25
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5044       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.04 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5044
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114427'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:27
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.3727       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.3727
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114429'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:29
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8767       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8767
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114431'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:31
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6453       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6453
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114433'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:33
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4101       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4101
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114435'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:35
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8509       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8509
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114437'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:37
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4771       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4771
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114439'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:39
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114441'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:41
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114443-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9877       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9877
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114445-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:45
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9685       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.35    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.38 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9685
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114447-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114449-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6271       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.89    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6271
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114451-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.8090       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.8090
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114453-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6113       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6113
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114455-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3599       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3599
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114457-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.2764       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.2764
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114459-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6176       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.04 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6176
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114501'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9661       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9661
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114503'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9958       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9958
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114505'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9961       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9961
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114507'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9998       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9998
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114509'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9989       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.11    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.14 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9989
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114511'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:11
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6979       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6979
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114513'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:13
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5343       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5343
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114515'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:15
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114517'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:17
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114519'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:19
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9996       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9996
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114522'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114524'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9807       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9807
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
