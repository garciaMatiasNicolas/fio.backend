Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114000-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5584       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5584
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114002-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1740       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1740
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114004'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6487       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6487
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114006'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.4%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4855       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4855
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114008'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7120       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7120
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114010'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9361       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9361
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114012'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6139       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.11 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6139
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114015'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:15
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.5039       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.08    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.09 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.5039
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114017'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.41 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:17
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3777       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.23    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.25 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3777
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114019'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:19
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9433       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9433
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114021'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:21
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4511       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4511
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114023'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:23
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8351       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.13    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.16 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8351
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114025'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:25
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7108       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7108
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114027-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:27
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114029-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:29
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3743       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.17 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3743
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114031-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:31
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9945       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9945
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114033-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:33
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.4094       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.4094
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114036'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4287       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.05    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.07 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4287
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114038'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7483       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7483
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114040'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9482       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9482
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114042'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.51 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6389       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6389
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114044'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.5335       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.5335
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114046-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8095       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8095
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114048-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114050'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7129       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7129
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114052'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5330       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5330
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114054-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.40 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114056'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:56
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114058'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:40:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-3.8728       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -3.8728
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114100'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6162       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6162
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114101-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9795       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.17 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9795
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114104'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3029       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3029
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114106'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.2651       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.2651
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114108'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1689       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1689
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114110'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114112'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1837       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1837
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114114'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9357       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9357
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114116'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7447       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7447
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114118'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.50 GB / 7.75 GB (32.3%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5059       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5059
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114120'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5632       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5632
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114122'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9372       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9372
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114124'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.1%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4671       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4671
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114126'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.39 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114128'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114130'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114132-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3473       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.12 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3473
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114134'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.1779       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.1779
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114136'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7325       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7325
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114138'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8244       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8244
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114140'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.05    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.08 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114143'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7438       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.21    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.24 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7438
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114145-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:45
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6806       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6806
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114147-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114149-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8058       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8058
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114151-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4619       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4619
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114153-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.38 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5095       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5095
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114155-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.2541       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.2541
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114157-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0884       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.01    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0884
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114159-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:41:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.0960       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.22    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.25 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.0960
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114201-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.8114       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.8114
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114203'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9104       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9104
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114205'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.0206       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.0206
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114207-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5153       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5153
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114209'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5457       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.27    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.30 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5457
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114212'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114214'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.48 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7907       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7907
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114216'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5277       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5277
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114218'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.37 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5384       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5384
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114220'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6568       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6568
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114222'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114224'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6141       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.75    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.77 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6141
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114226-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5465       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5465
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114228-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114230-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3498       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3498
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114232-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6891       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6891
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114234-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114236-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7273       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7273
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114238-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7483       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7483
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114240-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9841       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9841
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114242-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5262       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.92 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5262
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114244-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114246-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9976       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9976
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114248'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9566       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.24    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.27 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9566
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114250-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6690       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6690
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114252-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.11 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114255'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114257'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.2437       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.2437
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114259'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114301'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:01
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114303-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0311       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0311
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114305'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5225       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.10 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5225
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114307-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6821       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6821
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114309'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5133       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5133
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114311'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:11
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9982       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9982
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114314-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9945       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9945
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114316'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7054       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7054
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114318'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4403       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4403
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114320'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114322'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0511       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0511
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114324'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114326'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114328'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114330'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5946       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5946
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114332'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.6937       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.6937
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114334'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8968       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8968
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114336'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9896       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.10 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9896
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114338-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-3.1368       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.12 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -3.1368
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114341'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:41
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114342-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114344-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7393       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7393
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114346-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9299       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9299
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114348-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-5.9520       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -5.9520
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114350-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5453       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5453
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114352-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6446       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.31    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.34 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6446
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114355'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6113       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6113
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114357-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9354       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9354
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114359-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7281       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7281
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114402'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.5009       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.5009
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114404'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8563       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8563
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114406'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9861       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9861
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114408'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4209       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4209
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114410'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4570       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4570
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114412'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4880       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4880
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114413'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7763       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7763
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114415'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:15
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9409       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9409
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114417'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:17
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9294       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.05 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9294
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114419'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:19
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.1032       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.02 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.1032
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114421-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7344       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7344
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114423-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8373       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8373
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114426'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3840       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3840
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114428'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9753       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9753
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114430'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1785       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1785
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114432'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3121       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3121
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114434'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4419       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4419
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114435-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1321       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1321
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114438'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7921       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7921
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114440'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9779       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9779
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114442'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8178       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8178
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114443-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9974       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9974
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114446'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114447-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:48
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1132       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1132
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114450'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7968       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7968
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114452'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8993       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8993
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114454'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.5598       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.5598
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114456'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:56
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5908       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5908
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114458'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9889       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9889
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114500'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6788       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6788
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114502'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6251       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6251
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114504'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0067       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.07 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0067
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114506'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5987       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5987
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114508'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9948       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.15    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.19 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9948
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114510'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1431       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1431
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114512'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6150       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6150
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114514'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9448       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9448
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114516'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.24    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.27 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114518'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114520'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9999       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9999
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114522-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114524-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:25
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9467       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.02    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9467
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
