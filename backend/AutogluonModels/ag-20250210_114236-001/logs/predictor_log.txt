Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114236-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7583       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7583
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114238-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9809       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9809
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114240-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.36 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:40
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.3825       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.3825
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114242-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:42
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9884       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9884
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114244'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:44
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9992       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9992
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114246'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:46
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9828       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9828
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114247'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (36.0%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5384       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5384
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114250'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:50
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9870       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.22    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.25 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9870
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114252'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:52
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.4519       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.4519
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114254'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9345       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9345
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114256'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.47 GB / 7.75 GB (31.9%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:56
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-2.1276       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -2.1276
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114258'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:42:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0344       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.13    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.16 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0344
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114300-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.35 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.08 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114303'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:03
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5651       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.10    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.13 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5651
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114305-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:05
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114307'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:07
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.11    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.14 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114309-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:09
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0077       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.08 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0077
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114311-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:11
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3515       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3515
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114314-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6393       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.99    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6393
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114316-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8953       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.12    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.15 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8953
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114318-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.07 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114320-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.34 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114322-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114324-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114326-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114329'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.8%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:29
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9699       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.41    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.44 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9699
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114331'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:31
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114333'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:33
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0024       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.29    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.32 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0024
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114335'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:35
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9178       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9178
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114337'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:37
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5749       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5749
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114339'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.33 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:39
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7444       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7444
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114341-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:41
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.90    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.93 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114343'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.98    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.01 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114345'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:45
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6590       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6590
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114347'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.6316       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.6316
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114349'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4558       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4558
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114351'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4542       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.20    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.23 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4542
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114354'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.9%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:54
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6752       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.21    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.23 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6752
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114356'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.32 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:56
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.3114       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.3114
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114358'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:43:58
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0183       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0183
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114400'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:00
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9441       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9441
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114402-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0929       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0929
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114404-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9328       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9328
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114406-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1594       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1594
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114408-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7230       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7230
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114410-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8635       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8635
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114412-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.31 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8789       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8789
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114414'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8153       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8153
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114416'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5438       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5438
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114418'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:18
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3750       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3750
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114420'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:20
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.6765       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.6765
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114422'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:22
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9607       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9607
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114424'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:24
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9900       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9900
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114426-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:26
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8138       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.97    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8138
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114428-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.30 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:28
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9928       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9928
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114430-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:30
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3264       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3264
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114432-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:32
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.3752       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.3752
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114434-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:34
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0704       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0704
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114436'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:36
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7582       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.09    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.12 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7582
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114438-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:38
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7320       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.12    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.15 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7320
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114440-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:41
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114443'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:43
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9957       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.03    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.06 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9957
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114445'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.29 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:45
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114447'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.8%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:47
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9149       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.19    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.22 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9149
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114449'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:49
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4343       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.00    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.03 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4343
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114451'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:51
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4234       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.92    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.95 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4234
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114453'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:53
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.8477       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.8477
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114455'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:55
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.5673       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.5673
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114457'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:57
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.7809       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.91    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.94 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.7809
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114459'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.46 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.28 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:44:59
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.1438       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.87    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.90 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.1438
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114502-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.7%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:02
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9872       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9872
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114504-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:04
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.4822       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.4822
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114506-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:06
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9975       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9975
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114508-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:08
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9950       = Validation score (-MAPE)
	0.02    s     = Training runtime
	1.04    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.08 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9950
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114510-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:10
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.6676       = Validation score (-MAPE)
	0.02    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.99 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.6676
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114512-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.27 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:12
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9933       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9933
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114514-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:14
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.97 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114516-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:16
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.0000       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.95    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.0000
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114518-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:19
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-0.9994       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -0.9994
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114520-001'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:21
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.96    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 1.00 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114522-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:23
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	nan           = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.93    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.96 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: nan
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to '/home/mngarcia/apifio/fio.backend/backend/AutogluonModels/ag-20250210_114524-002'
=================== System Info ===================
AutoGluon Version:  1.2
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #141-Ubuntu SMP Fri Jan 10 21:18:28 UTC 2025
CPU Count:          4
GPU Count:          0
Memory Avail:       2.45 GB / 7.75 GB (31.6%)
Disk Space Avail:   12.26 GB / 34.36 GB (35.7%)
===================================================

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'hyperparameters': {'Chronos': {'dropout_rate': 0.3,
                                 'early_stopping': True,
                                 'hidden_size': 512,
                                 'learning_rate': 0.5,
                                 'num_layers': 50}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 12,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'MS'
Provided train_data has 133 rows, 1 time series. Median time series length is 133 (min=133, max=133). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-02-10 11:45:25
Models that will be trained: ['Chronos[autogluon__chronos-bolt-small]']
Training timeseries model Chronos[autogluon__chronos-bolt-small]. Training for up to 10.0s of the 10.0s of remaining time.
	-1.5890       = Validation score (-MAPE)
	0.01    s     = Training runtime
	0.94    s     = Validation (prediction) runtime
Not fitting ensemble as only 1 model was trained.
Training complete. Models trained: ['Chronos[autogluon__chronos-bolt-small]']
Total runtime: 0.98 s
Best model: Chronos[autogluon__chronos-bolt-small]
Best model score: -1.5890
Model not specified in predict, will default to the model with the best validation score: Chronos[autogluon__chronos-bolt-small]
